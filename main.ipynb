{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc83b07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T19:34:38.370840208Z",
     "start_time": "2026-02-14T19:34:34.748293094Z"
    }
   },
   "outputs": [],
   "source": [
    "# prelude\n",
    "import energnn\n",
    "from ase.visualize import view\n",
    "from ase.build import molecule\n",
    "import torch_geometric.loader as tcg_loader\n",
    "import torch as tc\n",
    "from functools import reduce\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da2da9",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This code only need to be executed at the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the files that needed.\n",
    "import energnn as erg\n",
    "erg.Toolbelt.download_environment_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52b1b1",
   "metadata": {},
   "source": [
    "# BasicGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset prepare.\n",
    "import pickle\n",
    "from energnn import DatasetAlexandria\n",
    "wbm = energnn.DatasetWBM()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecbc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(alex[60].y)\n",
    "#print(wbm[880].y)\n",
    "from energnn import DatasetAlexandria\n",
    "DatasetAlexandria(load_files=['005', '006', '007', '008', '009'], cutoff=8.0).dump(\"/home/aylwin/Projects/matbench/tmp/alexset005-009_cutoff8.dump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d419d2a7",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model\n",
    "model = energnn.ModelBasicGNNDeeper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "l1loss = tc.nn.L1Loss()\n",
    "mse_loss = tc.nn.MSELoss()\n",
    "def train_loss_fn(y, pred):\n",
    "    # This function will just train on e_above_hull aka y[:, 1]\n",
    "    return mse_loss(y[:, 1], pred[:, 1])\n",
    "def test_loss():\n",
    "    n = 0\n",
    "    energy_sum, e_above_hull_sum = 0, 0\n",
    "    num_Acc, n_Acc = 0, 0\n",
    "    def return_loss(y:tc.Tensor, pred:tc.Tensor)->dict:\n",
    "        nonlocal n, energy_sum, e_above_hull_sum, num_Acc, n_Acc\n",
    "        energy = l1loss(y[:, 0], pred[:, 0])\n",
    "        e_above_hull = l1loss(y[:, 1], pred[:, 1])\n",
    "        n+=1\n",
    "        # determine the Acc.  *----XOR---*\n",
    "        num_Acc += (lambda x, y:(1-(x+y)%2).sum())((y[:, 1]>0).int(), (pred[:, 1]>0).int())\n",
    "        #print((y[:, 1]>0).int().sum())\n",
    "        n_Acc += y.shape[0]\n",
    "        # add energy and e_above_hull_sum\n",
    "        energy_sum += float(energy)\n",
    "        e_above_hull_sum += float(e_above_hull)\n",
    "        return {\"avr_energy\":energy_sum/n, \"avr_e_above_hull\":e_above_hull_sum/n, \"avr_accuracy\":num_Acc/n_Acc}\n",
    "    return return_loss\n",
    "for epoch in range(40):\n",
    "    print(f\"Epoch {epoch} ================>\")\n",
    "    print(\"train:\")\n",
    "    for train_name in ('000-004', '005-009', '010-014'):\n",
    "        with open(f\"/home/aylwin/Projects/matbench/tmp/alexset{train_name}_cutoff8.dump\", 'rb') as f:\n",
    "            train_set = pickle.load(f)\n",
    "        model, log = mb.tcg_trainer(\n",
    "            model=model,\n",
    "            dataset=train_set,\n",
    "            optimizer=tc.optim.Adam(model.parameters(), lr=0.0001),\n",
    "            device='cuda',\n",
    "            epoch=1, \n",
    "            batch_size=64,\n",
    "            num_workers=4,\n",
    "            loss_fn = train_loss_fn\n",
    "        )\n",
    "    print(\"test:\")\n",
    "    mb.tcg_tester(\n",
    "        model=model,\n",
    "        dataset=wbm,\n",
    "        device='cuda',\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "        loss_fn=test_loss,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "l1loss = tc.nn.L1Loss()\n",
    "def test_loss():\n",
    "    n = 0\n",
    "    energy_sum, e_above_hull_sum = 0, 0\n",
    "    num_Acc, n_Acc = 0, 0\n",
    "    def return_loss(y:tc.Tensor, pred:tc.Tensor)->dict:\n",
    "        nonlocal n, energy_sum, e_above_hull_sum, num_Acc, n_Acc\n",
    "        energy = l1loss(y[:, 0], pred[:, 0])\n",
    "        e_above_hull = l1loss(y[:, 1], pred[:, 1])\n",
    "        n+=1\n",
    "        # determine the Acc.  *----XOR---*\n",
    "        num_Acc += (lambda x, y:(1-(x+y)%2).sum())((y[:, 1]>0).int(), (pred[:, 1]>0).int())\n",
    "        #print((y[:, 1]>0).int().sum())\n",
    "        n_Acc += y.shape[0]\n",
    "        # add energy and e_above_hull_sum\n",
    "        energy_sum += float(energy)\n",
    "        e_above_hull_sum += float(e_above_hull)\n",
    "        return {\"avr_energy\":energy_sum/n, \"avr_e_above_hull\":e_above_hull_sum/n, \"avr_accuracy\":num_Acc/n_Acc}\n",
    "    return return_loss\n",
    "energnn.tcg_tester(\n",
    "    model=model,\n",
    "    dataset=wbm,\n",
    "    device='cuda',\n",
    "    batch_size=256,\n",
    "    num_workers=32,\n",
    "    loss_fn=test_loss,\n",
    ")\n",
    "energnn.tcg_tester(\n",
    "    model=model,\n",
    "    dataset=alex_train,\n",
    "    device='cuda',\n",
    "    batch_size=256,\n",
    "    num_workers=32,\n",
    "    loss_fn=test_loss,\n",
    ")\n",
    "energnn.tcg_tester(\n",
    "    model=model,\n",
    "    dataset=alex_test,\n",
    "    device='cuda',\n",
    "    batch_size=256,\n",
    "    num_workers=32,\n",
    "    loss_fn=test_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea495b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the module.\n",
    "import pickle\n",
    "with open(\"/home/aylwin/Projects/matbench/tmp/good_model.ptm\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24fffdc",
   "metadata": {},
   "source": [
    "# EnerGNN\n",
    "---\n",
    "This model `.forward` will return the total energy for the structure input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072750c",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of how to train the EnerGNN model on the Alexandria dataset.\n",
    "import energnn as erg\n",
    "import torch as tc\n",
    "\n",
    "# Load the dataset.\n",
    "#dataset = erg.datasetAlexandriaNeo(load_files=['000'], cutoff=6.0) # This just run in the first time.\n",
    "dataset = erg.Toolbelt.pk_load(\"/Alexandria/000_cutoff6.dump\")\n",
    "\n",
    "# init model\n",
    "model = erg.EnerG()\n",
    "l1loss = tc.nn.L1Loss()\n",
    "for ep in range(20):\n",
    "    print(f\"Epoch {i} >>>>>>>>>>>>>> \")\n",
    "    for i in ['000','001', '002', '003', '004']:\n",
    "        dataset = erg.Toolbelt.pk_load(f\"/Alexandria/{i}_cutoff6.dump\")\n",
    "        model, log = erg.tcg_trainer(\n",
    "            model=model,\n",
    "            dataset=dataset,\n",
    "            optimizer=tc.optim.Adam(model.parameters(), lr=0.0001),\n",
    "            device='cuda',\n",
    "            epoch=1, \n",
    "            batch_size=64,\n",
    "            num_workers=4,\n",
    "            loss_fn = l1loss\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492af114",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118bf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you have a trained model.\n",
    "import energnn as erg\n",
    "import torch as tc\n",
    "import numpy as np\n",
    "model = erg.EnerG()#erg.Toolbelt.pk_load(\"/model.dump\")\n",
    "dataset = erg.datasetAlexandriaNeo(load_files=['001'], cutoff=6.0)\n",
    "def loss_fn_gen():\n",
    "    n = 0\n",
    "    loss_sum = 0\n",
    "    l1loss = tc.nn.L1Loss()\n",
    "    def ans(y, pred):\n",
    "        print(\"y>\", float(y), \"predict>\", float(pred)) if np.random.rand()>0.995 else \"\"\n",
    "        nonlocal n, loss_sum\n",
    "        ret = l1loss(y, pred)\n",
    "        loss_sum += ret\n",
    "        n+=1\n",
    "        return loss_sum/n\n",
    "    return ans\n",
    "erg.tcg_tester(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    loss_fn=loss_fn_gen,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b28e3",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import energnn as erg\n",
    "import torch as tc\n",
    "model = erg.Toolbelt.pk_load(\"/model.dump\")\n",
    "# Load the dataset.\n",
    "dataset = erg.datasetAlexandriaNeo(load_files=['001'], cutoff=6.0) # This just run in the first time.\n",
    "#dataset = erg.Toolbelt.pk_load(\"/Alexandria/000_cutoff6.dump\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404366e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read as ase_read # This function read .extxyz file to ase.atoms.Atoms\n",
    "import zipfile # because the ase dataset is in zip type.\n",
    "import pandas as pd\n",
    "import matbench_discovery.data as matbench_data\n",
    "DataFiles = matbench_data.DataFiles\n",
    "df_wbm_summary:pd.DataFrame = pd.read_csv(DataFiles.wbm_summary.path) # Load the wbm summary dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aylwin/Projects/matbench/.pixi/envs/default/lib/python3.12/site-packages/pymatgen/core/composition.py:1366: UserWarning: No Pauling electronegativity for Ne. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  syms: list[str] = sorted(sym_amt, key=lambda x: [get_el_sp(x).X, x])\n",
      "  0%|          | 0/100000 [00:00<?, ?it/s]/home/aylwin/Projects/matbench/.pixi/envs/default/lib/python3.12/site-packages/pymatgen/entries/computed_entries.py:369: FutureWarning: AffineScalarFunc.__bool__() is deprecated. In future releases it will defer to object.__bool__() and always return True.\n",
      "  corr = sum(ufloat(ea.value, ea.uncertainty) for ea in self.energy_adjustments if ea.value) or ufloat(\n",
      "100%|██████████| 100000/100000 [02:12<00:00, 752.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:59<00:00, 836.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aylwin/Projects/matbench/.pixi/envs/default/lib/python3.12/site-packages/pymatgen/core/composition.py:1366: UserWarning: No Pauling electronegativity for He. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  syms: list[str] = sorted(sym_amt, key=lambda x: [get_el_sp(x).X, x])\n",
      "100%|██████████| 100000/100000 [02:07<00:00, 785.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:29<00:00, 670.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:32<00:00, 471.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:54<00:00, 573.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aylwin/Projects/matbench/.pixi/envs/default/lib/python3.12/site-packages/pymatgen/core/composition.py:1366: UserWarning: No Pauling electronegativity for Ar. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  syms: list[str] = sorted(sym_amt, key=lambda x: [get_el_sp(x).X, x])\n",
      "100%|██████████| 100000/100000 [02:45<00:00, 602.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:51<00:00, 431.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexandria dataset ==== \n"
     ]
    }
   ],
   "source": [
    "import energnn as erg\n",
    "import torch as tc\n",
    "# Load the dataset.\n",
    "#dataset = erg.datasetAlexandriaNeo(load_files=['000'], cutoff=6.0) # This just run in the first time.\n",
    "for i in ['000', '001', '002', '003', '004', '005', '006', '007', '008', '009', '010']:\n",
    "    dataset = erg.datasetAlexandriaNeo(load_files=[i], cutoff=6.0)\n",
    "    erg.Toolbelt.pk_dump(dataset, f\"/{i}_cutoff6.dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb98d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
